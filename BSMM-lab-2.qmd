---
title: "BSMM-lab-2"
subtitle: "BSMM 8740 Fall 2023"
author: "Add your name here"
date: "Add the date here"
format: html
editor: visual
self-contained: true
---

## Setup

Load packages and data:

```{r load-pkg-data}
#| message: false
the_tate <- readr::read_delim("data/the-tate-collection.csv", ";", escape_double = FALSE, trim_ws = TRUE)
the_tate_artists <- readr::read_csv("data/the-tate-artists.csv")
```

## Exercises

### Exercise 1

```{r}
the_tate |> dplyr::summarize(
  artist=length(unique(artist)),
  min_year=min(year,na.rm =TRUE),
  max_year=max(year,na.rm = TRUE),
  min_acquisitionYear=min(acquisitionYear,na.rm=TRUE),
  max_acquisitionYear=max(acquisitionYear,na.rm=TRUE),
)
```

```{r}
the_tate |> DataExplorer::introduce()
```

```{r}
the_tate |> DataExplorer::plot_missing()
```

The `the_tate` dataset has \_\_\_ unique artists who worked from \_\_\_ to \_\_\_. The works were acquired between the years \_\_\_ and \_\_\_.

### Exercise 2

```{r}
the_tate |> dplyr::filter(is.na(year)) |> dplyr::distinct(artist)
```

```{r}
the_tate |> dplyr::filter(is.na(year)) |> dplyr::distinct(title)
```

```{r}
the_tate |> dplyr::filter(is.na(year))

#table(qaz$artist) |> tibble::tibble()
```

How number of works with missing dates is \_\_.

The number of artists whose works have missing dates is \_\_.

It would require resolving missing year data for only \_\_ artists resolve resolve at least 50% of the missing data.

The missing year data likely to be classified as \_\_\_\_.

### Exercise 3

```{r}
the_tate |> dplyr::group_by(artist) |>
dplyr::mutate(n=dplyr::n()) |>
  dplyr::select(artist,n) |> 
  dplyr::arrange(desc(n)) |>
  dplyr::distinct() |> 
  dplyr::ungroup() |> 
  dplyr::slice(c(1,10))
```

The artist with the most works in the Tate collection is \_\_\_.

The artist with the tenth-most works in the Tate collection is \_\_\_.

### Exercise 4

```{r}
the_tate %>%
  dplyr::group_by(artist) %>%
  dplyr::mutate(works_count = dplyr::n()) %>%
  dplyr::select(artist, works_count) %>%
  dplyr::arrange(desc(works_count)) %>%
  dplyr::distinct() %>%
  dplyr::ungroup() %>%
  dplyr::mutate(
    total = sum(works_count),
    pct = works_count / total
  )
```

The artist with the greatest number of works in the Tate collection represent \_\_\_% of the total number of works

### Exercise 5

```{r}
library(dplyr)
# Select artist and title columns and count the number of rows
count_all_rows <- the_tate %>%
  select(artist, title) %>%
  nrow()

count_all_rows
```

```{r}
# Select artist and title columns and count distinct pairs
distinct_artist_title <- the_tate %>%
  select(artist, title) %>%
  distinct() %>%
  nrow()

distinct_artist_title
```

```{r}
# Calculate the number of duplicated artist-title pairs
duplicated_count <- count_all_rows - distinct_artist_title

duplicated_count
```

There are \_\_ duplicate artist-title pairs

### Exercise 6

```{r}
library(dplyr)

# Calculate the area of each artwork and add it as a new column
the_tate <- the_tate %>%
  mutate(area = width * height)  # Assuming width and height columns exist

# Select artist, title, and area columns, and remove rows with NA values
selected_data <- the_tate %>%
  select(artist, title, area) %>%
  drop_na(.)

# Check if there is valid data after filtering and selecting
if (nrow(selected_data) > 0) {
  # Order the works by area in ascending order
  ordered_data <- selected_data %>%
    arrange(area)

  # Find the largest artworks
  largest_artworks <- ordered_data %>%
    slice_tail(n = 1)

  # Find the smallest artworks
  smallest_artworks <- ordered_data %>%
    slice_head(n = 1)
  
  # Print the results
  largest_artworks
  smallest_artworks
} else {
  cat("No valid data found after filtering and selecting.")
}
```

The artist with the largest work in the tate collection is \_\_\_

The artist with the smallest work in the collection is \_\_\_. The smallest work has area \_\_\_ $\text{cm}^2$

### Exercise 7

```{r}
library(dplyr)
```

```{r}
# Left join the_tate and the_tate_artists
the_tate <- left_join(the_tate, the_tate_artists, by = c("artistId" = "id"))

# Drop rows with NA gender values
the_tate <- the_tate %>%
  filter(!is.na(gender))
# Group by gender
grouped_data <- the_tate %>%
  group_by(gender)

# Show the resulting table
grouped_data
```

...

### Exercise 8

```{r}
library(readr)
```

```{r}
library(dplyr)
```

```{r}

```

The annual return in the SPX price in 2020 was \_\_\_%.

The corresponding price volatility was \_\_\_%.

### Exercise 9

```{r}
library(gt)
```

```{r}
# Create a data frame containing year, annual return, and annual volatility
data <- data.frame(
  year = c(2018, 2019, 2020, 2021, 2022, 2023),
  annual_return = c(0.1354964, -0.2295440, -0.1196547, -0.2284783, 0.2542846, NA),
  annual_std_dev = c(0.1211806, 0.1260414, 0.3507352, 0.1309710, 0.2416677, NA)
)

# Calculate the period volatility (standard deviation)
period_variance <- sum(data$annual_std_dev^2, na.rm = TRUE)
period_volatility <- sqrt(period_variance)

# Create a gt table
table <- gt(data) %>%
  tab_header(
    title = "SPX Price Summary",
    subtitle = "Annual Returns and Volatility (2018-2023)"
  ) %>%
  cols_label(
    year = "Year",
    annual_return = "Annual Return (%)",
    annual_std_dev = "Annual Volatility (%)"
  ) %>%
  fmt_number(
    columns = c("annual_return", "annual_std_dev"),
    decimals = 2
  ) %>%
  summary_rows(
    groups = TRUE,
    columns = c(annual_return, annual_std_dev),
    fns = list("Period Return" = sum(annual_return, na.rm = TRUE), "Period Volatility" = period_volatility)
  )

# Print the formatted table
print(table)
```

The period volatility was \_\_\_.\_%

### 
